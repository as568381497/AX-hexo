---
title: 阶段小结（一）
date: 2017-08-016 17:15:57
tags: [技术,总结,iOS]
category: [小结]
---
做的第一个APP叫《测量工具箱》，这个APP是我在快一个月的时候昨晚上架，一款工具类的APP，也是和别人合作做的，我负责一半功能的实现以及
最后的整合。

首先从功能上来说这个是整合的几个功能的APP，所以在整合别人功能的时候发现，在用storyboard的时候，将UI和功能代码分开写，再整合的时候，很简便，只需要根据情况适当的修改一点代码，就可以完成基本的整合，所以，我觉得这样写很好用。另外，在整合代码的时候，每个人的代码风格不一样，所以在看别人代码的时候，习惯别人的代码风格其实也不错，同时还可以收获很多东西，对自己的帮助还是挺大的。

仔细回想起来，自己做完这个APP，非常难的点其实没有，就有一些转不过弯的一些东西需要记住。

``` bash
1、在做横屏功能的时候，如果没有特别的情况，做的时候就按横屏的做，很方便。
2、开发中和给用户看到的效果，不一定是同一个，根据情况，偷偷做做弊，其实
可以让效果更简单。
3、代码要在不出错的基础上，要写的安全，优化、简洁（代码是给别人看的！）。
4、虽然现在大多都是用的ARC，但是，并不能完全保证内存不出问题。
5、要替用户想，尽量适合并提高用户体验。
6、找错的时候从出问题的地方打断点一级一级的向里面找，要相信自己。
7、项目的需求要跟产品事先沟通清楚，特别是细节，一定要搞清楚细节之后在做。
8、国际化语言的时候注意UI的适配。
9、系统提供的好评接口适用于10.3以上。
10、封装通用代码，注意安全。
```

项目中第一次接触相机权限，写下来，希望别人少踩点坑。

首先，iOS相机功能分两种实现方式，一种是系统的UIImagePickerController，一种是自定义的AVCaptureSession，我自己刚开始的时候一直以为UIImagePickerController是自己写的类。。。

另外，使用相机前，要获取相机的使用权限，在iOS10以后还需要在list文件中添加权限配置，不然程序会崩溃报错。


## 一、UIImagePickerController

### 1.跳转Controller实现两个协议UIImagePickerControllerDelegate和UINavigationControllerDelegate

### 2.实例化，实现协议跳转

``` bash
UIImagePickerController*pick = [[UIImagePickerControlleralloc]in
it];
pick.delegate=self;
pick.sourceType=UIImagePickerControllerSourceTypeCamera;
想要相机全屏，用这个showsCameraControls设置成NO后相机的UI会被隐藏了，但是底部的工具栏会留下一个个黑块，解决办法是一个取巧的办法，CGAffineTransformMakeScale

pick.showsCameraControls=NO;

```

但是这样就是放大的效果，有好有坏吧，不行就只能用自定义的了

``` bash
pick.cameraViewTransform=CGAffineTransformMakeScale(2,2);
[selfpresentViewController:pickanimated:YEScompletion:^{
}];
```
还有一种相机的实现方式

## 二、AVCaptureSession

### 1，导入AVfounation包

### 2.实例化
``` bash
//1.创建媒体管理会话
AVCaptureSession*session = [[AVCaptureSessionalloc]init];
//判断分辨率是否支持1280*720，支持就设置为1280*720
if( [sessioncanSetSessionPreset:AVCaptureSessionPreset1280x720] )
{
session.sessionPreset=AVCaptureSessionPreset1280x720;
}
//2.获取后置摄像头设备对象
AVCaptureDevice*device =nil;
NSArray*cameras = [AVCaptureDevicedevicesWithMediaType:AVMediaTyp
eVideo];
for(AVCaptureDevice*cameraincameras) {
if(camera.position==AVCaptureDevicePositionBack) {//取得后置摄像头
device = camera;
}
}
if(!device) {
NSLog(@"取得后置摄像头错误");
return;
}
//3.创建输入数据对象
NSError*error =nil;
AVCaptureDeviceInput*captureInput = [[AVCaptureDeviceInputalloc]
initWithDevice:device
error:&error];
if(error) {
NSLog(@"创建输入数据对象错误");
return;
}
//4.创建输出数据对象
AVCaptureStillImageOutput*imageOutput = [[AVCaptureStillImageOutp
utalloc]init];
NSDictionary*setting =@{AVVideoCodecKey:AVVideoCodecJPEG};
[imageOutputsetOutputSettings:setting];
//5.添加输入数据对象和输出对象到会话中
if([sessioncanAddInput:captureInput]) {
[sessionaddInput:captureInput];
}
if([sessioncanAddOutput:imageOutput]) {
[sessionaddOutput:imageOutput];
}
//6.创建视频预览图层
AVCaptureVideoPreviewLayer*videoLayer =
[[AVCaptureVideoPreviewLayeralloc]initWithSession:session];
self.view.layer.masksToBounds=YES;
videoLayer.frame=self.view.bounds;
videoLayer.videoGravity=AVLayerVideoGravityResizeAspectFill;
[self.view.layeraddSublayer:videoLayer];
//这里需要设置相机开始捕捉画面
[sessionstartRunning];//开始捕捉
```
